---
layout: archive
title: "Resources"
permalink: /resources/
author_profile: true
redirect_from: 
---

<meta name="description"
  content="Open-source Code and Datasets for Person Re-ID and Person Search"/>

<meta name="keywords" content="Code and Dataset, Person Re-ID, Object Re-ID, Person Retrieval, Domain Adaptation and Person Search" />


- MALS Dataset. 

<table class="imgtable">
	<tbody><tr><td>
    <img src="https://github.com/Shuyu-XJTU/APTM/blob/main/assets/examples.jpg?raw=true" alt="MALS"> &nbsp;</td>
    <td align="left"> <strong><a href="https://github.com/Shuyu-XJTU/APTM"> [website]</a></strong> 
We present a large Multi-Attribute and Language Search dataset for text-based person retrieval, called MALS, and explore the feasibility of performing pre-training on both attribute recognition and image-text matching tasks in one stone. In particular, MALS contains 1, 510, 330 image-text pairs, which is about 37.5× larger than prevailing CUHK-PEDES, and all images are annotated with 27 attributes.
    </td>
</tr></tbody></table>

- University-1652 Dataset. 
<table class="imgtable">
	<tbody><tr><td>
<img src="https://user-images.githubusercontent.com/8390471/192081571-56b84733-238a-45e1-bbf4-988067dbcf51.png" alt="University-1652"> &nbsp;</td>
    <td align="left"> <strong><a href="https://github.com/layumi/University1652-Baseline"> [website]</a></strong>  <strong><a href="https://github.com/layumi/University1652-Baseline/tree/master/State-of-the-art"> [SoTA]</a></strong> 
We collect 1652 buildings of 72 universities around the world. University-1652 contains data from three platforms, i.e., synthetic drones, satellites and ground cameras of 1,652 university buildings around the world. To our knowledge, University-1652 is the first drone-based geo-localization dataset and enables two new tasks, i.e., drone-view target localization and drone navigation.
    </td>
</tr></tbody></table>


- Market-1501 and DukeMTMC-reID Attribute Datasets.  
<table class="imgtable">
	<tbody><tr><td>
<img src="https://github.com/vana77/Market-1501_Attribute/raw/master/sample_image.jpg?raw=true" alt="Pedestrian Attribute"> &nbsp; </td>
    <td align="left"> <strong><a href="https://vana77.github.io"> [website]</a></strong>
We manually annotate attribute labels for two large-scale re-ID datasets, and systematically investigate how person re-ID and attribute recognition benefit from each other. 
    </td>
</tr></tbody></table>

- 3D Market-1501 Dataset.  
<table class="imgtable">
	<tbody><tr><td>
<img src="https://user-images.githubusercontent.com/8390471/208151146-b8564829-bd61-484d-850f-61ba75216388.jpg" alt="3D Market"> &nbsp;</td>
   <td align="left"> <strong><a href="https://github.com/layumi/person-reid-3d"> [website]</a></strong> 
You could find the point-cloud format Market-1501 Dataset at https://github.com/layumi/person-reid-3d.
    </td>
</tr></tbody></table>

- DG-Market Dataset.
<table class="imgtable">
	<tbody><tr><td>
<img src="https://user-images.githubusercontent.com/8390471/192081605-0c8a246f-e54c-41c7-9936-5ba8e22f5192.png" alt="DG-Market"> &nbsp;</td>
<td align="left"> We provide our generated images and make a large-scale synthetic dataset called DG-Market. This dataset is generated by our [DG-Net](https://arxiv.org/abs/1904.07223) and consists of 128,307 images (613MB), about 10 times larger than the training set of original Market-1501 (even much more can be generated with DG-Net). It can be used as a source of unlabeled training dataset for semi-supervised learning. You may download the dataset from <a href="https://drive.google.com/file/d/126Gn90Tzpk3zWp2c7OBYPKc-ZjhptKDo/view?usp=sharing">[Google Drive]</a> (or <a href="https://pan.baidu.com/s/1n4M6s-qvE08J8SOOWtWfgw">[Baidu Disk]</a>) password: qxyh).
    </td>
</tr></tbody></table>

- HQ-Market Super-resolution Dataset. <strong><a href="https://github.com/layumi/HQ-Market"> [website]</a></strong>
- DukeMTMC-reID Dataset.  <strong><a href="https://github.com/layumi/Duke_evaluation"> [website]</a></strong>  <strong><a href="https://github.com/layumi/Person_reID_baseline_pytorch/tree/master/leaderboard"> [SoTA]</a></strong> 
- DukeMTMC-Pose Dataset.  <strong><a href="https://github.com/layumi/DukeMTMC-Pose"> [website]</a></strong> 
- UTS Person-reID Tutorial.  <strong><a href="https://github.com/layumi/Person_reID_baseline_pytorch/tree/master/tutorial"> [website]</a></strong> 

### Awesome Lists
- [Awesome Segmentation Domain Adaptation](https://github.com/layumi/Seg-Uncertainty/tree/master/awesome-SegDA)
- [Awesome Vehicle Retrieval](https://github.com/layumi/Vehicle_reID-Collection)
- [Awesome Fools](https://github.com/layumi/Awesome-Fools)
- [Awesome Geo-localization](https://github.com/layumi/University1652-Baseline/tree/master/State-of-the-art) 

### Motivations
![](https://zdzheng.xyz/files/optimizer.gif)
- [The illustrated guide to a Ph.D.](https://matt.might.net/articles/phd-school-in-pictures/)
-  <strong><a href="https://www.evernote.com/shard/s150/sh/3de79ff0-5778-417c-9bcb-6c0111a26694/29958003bb71992667ce3f42fd4ca875"> 熊辉: 为什么人前进的路总是被自己挡住 </a></strong> 
-  <strong><a href="https://zdzheng.xyz/files/road.pdf">陈海波: 一名系统研究者的攀登之路</a></strong> 
-  <strong><a href="https://www.douban.com/note/218498393/">勇气与真意——关于围棋的八卦</a></strong>
-  [山世光：致联系报考我免试研究生的同学们](https://blog.csdn.net/GarfieldEr007/article/details/51018552) 

### How to 
- [How to research? Jianxiong Xiao]("https://zdzheng.xyz/files/lecture21_how2research.pdf")
- [How to have productive meetings with busy mentors?](http://kordinglab.com/2021/06/30/meeting-with-mentors.html)
- [How to start writing papers?](http://kordinglab.com/2016/01/14/writing-guide.html)
- [How to rebuttal? Devi Parikh](https://deviparikh.medium.com/how-we-write-rebuttals-dc84742fece1)